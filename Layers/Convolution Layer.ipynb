{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Convolution?\n",
    "Classifying Images with a Fully Connected Network is bad for 2 reasons.\n",
    "- There is no sense of \"localization\"\n",
    "- The number of parameters explodes\n",
    "\n",
    "#### Localization\n",
    "Our input image is a reactangle\n",
    "```\n",
    "[[(0, 0), (1, 0), (2, 0)],\n",
    " [(0, 1), (1, 1), (2, 1)],\n",
    " [(0, 2), (1, 2), (2, 2)],\n",
    " [(0, 3), (1, 3), (2, 3)]]\n",
    "```\n",
    "by unraveling the image into a vector, we lose content (note raster scanning can help)\n",
    "```\n",
    "[(0, 0), (1, 0), (2, 0), (0, 1), (1, 1), (2, 1), (0, 2), (1, 2), (2, 2), (0, 3), (1, 3), (2, 3)]\n",
    "```\n",
    "\n",
    "#### Number of Parameters\n",
    "We are passing an image $x_i = (LxWx3)$, thus each Neuron in the first hidden layer must have $L\\cdot W \\cdot 3$ weights. (Note that each \"Neuron\" in this context would be equivalent to the first row in our Linear Layer). Thus a 32x32 image would require only 3,072 weights, but a 200x200 image would require 120,000 weights. \n",
    "\n",
    "And obviously we would have more than one hidden layer, and the number of neurons may even increase between layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Operation (Basic)\n",
    "The solution is to apply an operation called **convolution** with these things called **filter (s)**.\n",
    "\n",
    "A filter $F$ is simply a small matrix (eg 5x5x3). During convolution we will take the dot product of $F$, and a subsection of the image, $I$ (eg 5x5x3) to create an **activation map**, $A$.\n",
    "```\n",
    "    [0, 1, 2]\n",
    "    [3, 4, 5]     [0, 1]     [4, 6]\n",
    "I = [6, 7, 8] F = [1, 0] A = [10, 12]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuition\n",
    "We are trying to solve the above problems of **Localization**, and **Number of Parameters**\n",
    "\n",
    "#### Localization\n",
    "This has obviously improved. By taking the dot product over sections of an image, our filters are effectively trained to pick up on special details (eg. corners, blobs of color)\n",
    "\n",
    "#### Number of Parameters\n",
    "Filters are typically small, for instance 5x5x3, thus the number of parameters has been greatly reduced. Even with 12 filters in a layer we would end up with only 900 weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution (Medium)\n",
    "\n",
    "We skipped a couple things in the basic overview.\n",
    "\n",
    "#### Stride\n",
    "Say we have an Image, $I$, and a Filter $F$\n",
    "```\n",
    "    [0, 1, 2, 3]\n",
    "    [4, 5, 6, 7]\n",
    "    [8, 9, 10, 11]       [0, 1]\n",
    "I = [12, 13, 14, 15] F = [1, 0]\n",
    "```\n",
    "\n",
    "Typically we would convolve as follows\n",
    "```\n",
    "[0, 1]   [0, 1]\n",
    "[4, 5] * [1, 0]\n",
    "\n",
    "[1, 2]   [0, 1]\n",
    "[5, 6] * [1, 0]\n",
    "\n",
    "[2, 3]   [0, 1]\n",
    "[6, 7] * [1, 0]\n",
    "...\n",
    "```\n",
    "\n",
    "This is a Stride of 1. If Stride were 2 then we would convolve as\n",
    "```\n",
    "[0, 1]   [0, 1]\n",
    "[4, 5] * [1, 0]\n",
    "\n",
    "[2, 3]   [0, 1]\n",
    "[6, 7] * [1, 0]\n",
    "...\n",
    "```\n",
    "\n",
    "#### Zero Padding\n",
    "Certain Filter Dimensions or Strides do not work so we add a border of Zero's to the image, e.g\n",
    "```\n",
    "[0, 0, 0, 0, 0, 0]\n",
    "[0, 0, 1, 2, 3, 0]\n",
    "[0, 4, 5, 6, 7, 0]\n",
    "[0, 8, 9, 10, 11, 0]\n",
    "[0, 12, 13, 14, 15, 0]\n",
    "[0, 0, 0, 0, 0, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Formula\n",
    "If the input image is $WxWx3$, and we have $KxKx3$ filters, with a stride of $S$, and padding $P$, then the output activation map will be shape\n",
    "$$\\frac{(W - K + 2\\cdot P)}{S} + 1$$\n",
    "\n",
    "(note that this can also be used to check when padding will be needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Example\n",
    "Lets reproduce the 2d convolution we did above\n",
    "```\n",
    "    [0, 1, 2, 3]\n",
    "    [4, 5, 6, 7]\n",
    "    [8, 9, 10, 11]       [0, 1]\n",
    "I = [12, 13, 14, 15] F = [1, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = torch.Tensor([[[[i + j*3 for i in range(3)] for j in range(3)]]])\n",
    "F = torch.Tensor([[[[0, 1], [1, 0]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = f.conv2d(input=I, weight=F, bias=None, stride=1, padding=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example we declared our filter as\n",
    "```\n",
    "[[[[0, 1], [1, 0]]]] # shape = (1, 1, 2, 2)\n",
    "\n",
    "```\n",
    "\n",
    "Rather than simply as\n",
    "```\n",
    "[[0, 1], \n",
    " [1, 0]]\n",
    "```\n",
    "\n",
    "As one might expect, this is because in training we typically pass multiple filters, eg\n",
    "```\n",
    "[[[[1., 1., 1.],\n",
    "  [1., 0., 1.],\n",
    "  [1., 1., 1.]],\n",
    "\n",
    " [[0., 1., 0.],\n",
    "  [1., 0., 1.],\n",
    "  [0., 1., 0.]]]]\n",
    "```\n",
    "\n",
    "(and the data must be 4 dimensional on acccount of training data being passed in mini-batches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
